{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.appName('TextCleaning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "list_punct=list(string.punctuation)\n",
    "lines=sc.textFile('data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |    words|       true|\n",
      "+--------+---------+-----------+\n",
      "\n",
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|     guitar|  421|\n",
      "|    playing|   68|\n",
      "|       play|   57|\n",
      "|    singing|   48|\n",
      "|       like|   40|\n",
      "|performance|   38|\n",
      "|   kyungsoo|   38|\n",
      "|   chanyeol|   38|\n",
      "|     missed|   38|\n",
      "|     tuning|   36|\n",
      "|       drop|   36|\n",
      "|       name|   33|\n",
      "|       alex|   33|\n",
      "|   pitching|   33|\n",
      "|     vocals|   33|\n",
      "|        dog|   33|\n",
      "|  waannnnma|   33|\n",
      "|       kiss|   33|\n",
      "|        one|   28|\n",
      "|        new|   27|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = ( lines.flatMap(lambda line: line.split(' '))\n",
    "     .filter(lambda punct: punct not in list_punct)\n",
    "     .filter(lambda word: word.lower() not in stop_words and word != '')\n",
    "     .filter(lambda word: word[0:4].lower() != 'b\\'rt' and word[0:4].lower() != 'b\"rt')\n",
    "     .filter(lambda word: word[0] != '@' and word[0] != '\\\\' and word[0] != '#' and word[0] != '&')\n",
    "     .filter(lambda word: word[0:8] != 'https://' and word[0:7] != 'http://')\n",
    "     .filter(lambda word: len(word) > 2)\n",
    "     .filter(lambda word: '\\\\' not in word)\n",
    "     .map(lambda word: (word.lower(), 1))\n",
    "     .reduceByKey(lambda x, y: x + y))\n",
    "    \n",
    "df = spark.createDataFrame(m, ['word', 'count'])\n",
    "df.createOrReplaceTempView('words')\n",
    "spark.sql( 'show tables from default' ).show()\n",
    "words = spark.sql('select word, count from words order by count desc limit 20')\n",
    "words.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
