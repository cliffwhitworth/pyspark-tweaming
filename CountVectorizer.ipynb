{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, CountVectorizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "import string\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.appName('CountVectorizer').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|tweet                                                                                               |\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|Listening on port: 9999                                                                             |\n",
      "|Received request from: ('127.0.0.1', 46120)                                                         |\n",
      "|If Ashley Purdy left BVB, how am I gonna look at naked women on a bass guitar when I see them live?'|\n",
      "|@jennyhalasz I probably would have gone with this. Or more guitar stuff. https://t.co/Iuao7j0Dro'   |\n",
      "|@Starecrows the opening with the guitar part, and it just loops with no end'                        |\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines=sc.textFile('data.txt')\n",
    "df = (lines.flatMap(lambda line: line.split('b\\''))\n",
    "      .filter(lambda line: '\\\\' not in line)\n",
    "      .filter(lambda line: line != '')\n",
    "      .map(lambda line: (line, )).toDF(['tweet']))\n",
    "\n",
    "df.createOrReplaceTempView('tweets')\n",
    "tweets = spark.sql('select * from tweets')\n",
    "tweets.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               tweet|               words|\n",
      "+--------------------+--------------------+\n",
      "|Listening on port...|[listening, on, p...|\n",
      "|Received request ...|[received, reques...|\n",
      "|If Ashley Purdy l...|[if, ashley, purd...|\n",
      "|@jennyhalasz I pr...|[jennyhalasz, i, ...|\n",
      "|@Starecrows the o...|[starecrows, the,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol='tweet', outputCol='words', pattern='\\\\W')\n",
    "regexTokenized = regexTokenizer.transform(tweets)\n",
    "regexTokenized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|            filtered|\n",
      "+--------------------+--------------------+\n",
      "|[listening, on, p...|[listening, port,...|\n",
      "|[received, reques...|[received, reques...|\n",
      "|[if, ashley, purd...|[ashley, purdy, l...|\n",
      "|[jennyhalasz, i, ...|[jennyhalasz, pro...|\n",
      "|[starecrows, the,...|[starecrows, open...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol='words', outputCol='filtered')\n",
    "stop_words_removed = remover.transform(regexTokenized.select(['words']))\n",
    "stop_words_removed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|               words|            filtered|             cleaned|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[listening, on, p...|[listening, port,...|[listening, port,...|\n",
      "|[received, reques...|[received, reques...|[received, reques...|\n",
      "|[if, ashley, purd...|[ashley, purdy, l...|[ashley, purdy, l...|\n",
      "|[jennyhalasz, i, ...|[jennyhalasz, pro...|[jennyhalasz, pro...|\n",
      "|[starecrows, the,...|[starecrows, open...|[starecrows, open...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "cleaned_df = stop_words_removed.withColumn('cleaned', f.expr('filter(filtered, x -> not(length(x) < 3))'))\n",
    "cleaned_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|     cleaned|count(1)|\n",
      "+------------+--------+\n",
      "|       still|       5|\n",
      "|trustinjonas|       2|\n",
      "|    received|       1|\n",
      "|        bone|       1|\n",
      "|    keyboard|       1|\n",
      "+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, count\n",
    "\n",
    "sum_of_words = cleaned_df.withColumn('cleaned', explode(col('cleaned'))).groupBy('cleaned').agg(count('*'))\n",
    "sum_of_words.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357\n"
     ]
    }
   ],
   "source": [
    "num_features = sum_of_words.groupBy().sum().collect()[0][0]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------\n",
      " cleaned | [listening, port, 9999]                                                                  \n",
      " vectors | (166,[],[])                                                                              \n",
      "-RECORD 1-------------------------------------------------------------------------------------------\n",
      " cleaned | [received, request, 127, 46120]                                                          \n",
      " vectors | (166,[],[])                                                                              \n",
      "-RECORD 2-------------------------------------------------------------------------------------------\n",
      " cleaned | [ashley, purdy, left, bvb, gonna, look, naked, women, bass, guitar, see, live]           \n",
      " vectors | (166,[0,24,44,53],[1.0,1.0,1.0,1.0])                                                     \n",
      "-RECORD 3-------------------------------------------------------------------------------------------\n",
      " cleaned | [jennyhalasz, probably, gone, guitar, stuff, https, iuao7j0dro]                          \n",
      " vectors | (166,[0,1,105],[1.0,1.0,1.0])                                                            \n",
      "-RECORD 4-------------------------------------------------------------------------------------------\n",
      " cleaned | [starecrows, opening, guitar, part, loops, end]                                          \n",
      " vectors | (166,[0,34],[1.0,1.0])                                                                   \n",
      "-RECORD 5-------------------------------------------------------------------------------------------\n",
      " cleaned | [jamesbut_, bass, guitar, world, smallest, violin]                                       \n",
      " vectors | (166,[0,24,119,146],[1.0,1.0,1.0,1.0])                                                   \n",
      "-RECORD 6-------------------------------------------------------------------------------------------\n",
      " cleaned | [merle, travis, dark, dungeon, solo, guitar, 1951, via, countrymusic, https, kqoqnumt5g] \n",
      " vectors | (166,[0,1,3,25],[1.0,1.0,1.0,1.0])                                                       \n",
      "-RECORD 7-------------------------------------------------------------------------------------------\n",
      " cleaned | [zager, guitar, giveaway, https, oa3pp8mjie, via, zager_guitars]                         \n",
      " vectors | (166,[0,1,3,101,110,164],[1.0,1.0,1.0,1.0,1.0,1.0])                                      \n",
      "-RECORD 8-------------------------------------------------------------------------------------------\n",
      " cleaned | [wed, grossmont, guitar, ensemble, https, audy2ffwnv]                                    \n",
      " vectors | (166,[0,1,149],[1.0,1.0,1.0])                                                            \n",
      "-RECORD 9-------------------------------------------------------------------------------------------\n",
      " cleaned | [gtraddict, impress, people, play, guitar, guitarist, guitarplayer, https, tvpbqrajnm]   \n",
      " vectors | (166,[0,1,2,35,50,75,85,98,133],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                   \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol='cleaned', outputCol='vectors', vocabSize=num_features, minDF=2.0)\n",
    "\n",
    "model = cv.fit(cleaned_df)\n",
    "\n",
    "cnt_vect = model.transform(cleaned_df)\n",
    "cnt_vect.select('cleaned', 'vectors').show(n=10, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word\n",
       "0  guitar\n",
       "1   https\n",
       "2    play\n",
       "3     via\n",
       "4     one"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "terms_df = pd.DataFrame(model.vocabulary, columns=['word'])\n",
    "terms_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
